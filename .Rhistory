## (3) ---- 가변수 활용하기 ----
ts_data = ts(data = as.numeric(KOSPI$KS11.Close),
frequency = 20)
# 코로나 급락시점은 0으로 맞춤
t = time(ts_data)
t.break = data.frame(t, ts_data)
t.break[t.break$t < 3.65,] = 0
t.break[t.break$t > 3.75,] = 0
tb1 = ts(t.break$t, frequency = 20)
# 기존 방식
fit.t = tslm(ts_data ~ t)
# 아카이케의 정보기준
# 참고자료: https://otexts.com/fppkr/selecting-predictors.html
AIC(fit.t)
# 가변수를 활용한 방식
fit.tb = tslm(ts_data ~ t + I(t^2) + I(t^3) + I(tb1^3))
AIC(fit.tb)
# 두 데이터의
ggplot(ts_data, aes(x = time(ts_data))) +
geom_line(aes(y = ts_data)) +
geom_line(aes(y = fit.t$fitted.values),
color = "#A37E03", size = 1) +
geom_line(aes(y = fit.tb$fitted.values),
color = "#0A29F0") +
theme_minimal()
new = data.frame(t = t[length(t)] + seq(1, by = 0.05, length.out = 20))
forecast(fit.t, newdata = new)
# 7.6  auto.arima를 이용하여 KOSPI 지수 예측하기
# 7.6.1  정상성과 차분
library(urca)
KOSPI = getSymbols("^KS11",
from = "2020-01-01",
to = "2021-01-31",
auto.assign = FALSE)
ts_kospi = ts(as.numeric(KOSPI$KS11.Close), frequency = 20)
ur_test = ur.kpss(ts_kospi)
summary(ur_test)
dif_1 = diff(ts_kospi, differences = 1)
ur_test2 = ur.kpss(dif_1)
ur_test2
dif_2 = diff(ts_kospi, differences = 2)
ur_test3 = ur.kpss(dif_2)
summary(ur_test3)
log_dif_2 = diff(log(ts_kospi), differences = 2)
ur_test4 = ur.kpss(log_dif_2)
summary(ur_test4)
# 7.6.2  auto.arima 활용하기
ggplot(ts_kospi, aes(x = time(ts_kospi))) +
geom_line(aes(y = ts_kospi))
library(forecast)
fit = auto.arima(ts_kospi)
fit
checkresiduals(fit)
fore = data.frame(forecast(fit, h = 5))
fore
ggplot(fore, aes(x = index(fore), y = Point.Forecast)) +
geom_line() +
geom_ribbon(aes(ymin = Lo.95, ymax = Hi.95), alpha = 0.25) +
geom_ribbon(aes(ymin = Lo.80, ymax = Hi.80), alpha = 0.5)
export KAGGLE_USERNAME=snapbuy
export KAGGLE_KEY=5f44a81bbd240beca69cafe06b622188
library(caret, lib.loc = "/Library/Frameworks/R.framework/Versions/4.1/Resources/library")
#### 데이터 전처리 시 기본적원 방법 정리 ####
#### (2) 데이터 불러오기 ####
getwd()
loan_data = read.csv("data/raw_loan_data.csv", stringAsFators - FALSE)
loan_data = read.csv("data/raw_loan_data.csv", stringAsFactors - FALSE)
#### (3) 데이터 탐색하기 ####
# Load the gmodels package
library(gmodels)
#### (3) 데이터 탐색하기 ####
# Load the gmodels package
install.packages("gmodels")
library(gmodels)
#### 데이터 전처리 시 기본적원 방법 정리 ####
#### (2) 데이터 불러오기 ####
getwd()
setwd("/Volumes/T7/git/kma)
loan_data = read.csv("data/raw_loan_data.csv", stringAsFactors - FALSE)
#### (3) 데이터 탐색하기 ####
# Load the gmodels package
install.packages("gmodels")
library(gmodels)
# 종속변수가 되는 loan_status에 대해 데이터를 탐색합니다.
# 0의 의미는 채무 이행, 즉 대출금을 상환한 사람 숫자
# 1의 의미는 채무 불이행, 즉 대출금을 상환하지 못한 사람 숫자
?CrossTable
# prop.r의 경우, y값에 대한 x의 비율을 알 수 있음
# prop.c의 경우, 각 변수에 대한 비율을 알 수 있음
# prop.t의 경우, 전체 테이블의 비율을 알 수 있음
# prop.chisq의 경우 각 셀에 해당하는 카이제곱의 비율을 알 수 있음
# But, 각 변수, 전체 테이블, 카이제곱은 현재로써는 필요 없음
# 위 데이터 탐색에서 봐야 하는 것은 loan_status기준으로 데이터가 불균형하다는 것에 있음
# 분류 문제 다룰 시, 이와 같은 문제에 직면하는 경우가 많음.
#### (4) 데이터 시각화 하기 ####
# 수치형 데이터 - 히스토그램으로 대출금액 파악하기
#### (5) 이상치 제거 ####
# 시각화의 목적은 크게 두가지가 있다.
# 변수간의 관계성, 분포도 등 확인이 필요하다.
# 가장 좋은 것 중 하나는, missing data를 잡아내거나, 이상치를 잡아낼 수 있다.
# 산점도를 확인해보자
# 위 그래프에서 보이는 것처럼 age가 150에 가까운 데이터가 존재했다.
# 이상치에 대한 접근방법은 크게 2가지다
# (1) 도메인 전문가의 직관 및 의견
# (2) 통계적인 방법으로 제거
# (3) (1) + (2)을 혼합해서 사용하는 것
# 즉, 현업 담당자와 커뮤니케이션을 통해서 이상치를 제거한다.
# (1) 방법으로 제거
# 상식적으로 140세는 존재할 수 없다. (현재 의학으로는..)
# 다행히, 데이터가 1개만 존재하기 때문에, 삭제해도 무방하다.
# 이상치인 데이터의 Index를 찾아본다.
# 이 코드는 특정 Index를 유용하기 때문에 꼭 참고한다.
# 19486번째 사람인 것 확인
# 새로운 데이터를 만든다. loan_data2 로 저장한다.
# (2) 방법으로 제거
# 사분위수 Q3 + 1.5 * IQR 보다 큰것을 이상치로 판단 후 제거
# 이상치로 측정된 전체 Index는 1382개수로 확인됨
# 이상치 제거한 데이터
# 이 데이터는 사용하지 않을 것이기 때문에 제거
# 위와 같은 방법으로 이상치를 제거할 수 있다.
#### (6) 결측치 처리 방법 ####
# int_rate와 emp_length에 결측치가 제법 많음이 보인다.
# int_rate의 경우 2776
# emp_length의 경우 809
# 만약 여러분이, 데이터 처리를 해야 하는 상황이라면 어떻게 해야 할까요?
# 크게 3가지 방법이 있습니다.
# 첫번째, 행 또는 열 삭제
# 두번째, 대치법
# 세번째, 그 상태로 유지하는 법
# 어떤 방법이 더 좋은지는 상황에 따라 다릅니다.
# 여기서는 각각의 방법에 대해 코드 처리법을 알려드립니다.
# 이 원칙은 어떤 언어를 사용해도 동일하게 적용됩니다.
#### (6-1) 결측치 제거 ####
## 행 제거
# 결측치에 해당하는 Index 확인
# 2776개 확인
# Index 활용 제거
## 변수 제거
# 간단하게 변수 제거
#### (6-2) 중간값 대치 ####
# 우선, 결측치를 제외한 중간값을 구한다.
# 다른 데이터로 변환
# 결측치 index에 중간값 대치
# 요약 통계량으로 결측치 유무 재확인
# Tip: 중간값 대치가 꼭 합리적인 것은 아닙니다.
# R에서는 다중대치법에 관한 패키지가 있습니다.
# 이 부분은 개인적으로 소화하시는 것으로 남겨 놓겠습니다.
# https://www.analyticsvidhya.com/blog/2016/03/tutorial-powerful-packages-imputing-missing-values/
#### (6-3) 결측치를 사용하기 ####
# 단, 중요한 것은 수치형이나 범주형이나, NA를 하나의 값으로 생각하고 치환하는 것이 핵심 포인트입니다.
# 근속년수에 따른 데이터를 변환하면 'Missing'으로 하나의 의미있는 값으로 치환할 수 있습니다.
# 강사가 가장 좋아하는 소스코드 중의 하나입니다.
# End of Document
install.packages("gmodels")
setwd("/Volumes/T7/git/kma")
loan_data = read.csv("data/raw_loan_data.csv", stringAsFactors = FALSE)
library(gmodels)
CrossTable(x = loan_data$loan_status)
loan_data = read.csv("data/raw_loan_data.csv", stringAsFactors = FALSE)
loan_data = read.csv("data/raw_loan_data.csv", stringAsFactors = FALSE)
loan_data = read.csv("data/raw_loan_data.csv")
CrossTable(x = loan_data$loan_status)
# 0의 의미는 채무 이행, 즉 대출금을 상환한 사람 숫자
# 1의 의미는 채무 불이행, 즉 대출금을 상환하지 못한 사람 숫자
library("ggplo2")
# 0의 의미는 채무 이행, 즉 대출금을 상환한 사람 숫자
# 1의 의미는 채무 불이행, 즉 대출금을 상환하지 못한 사람 숫자
library("ggplot")
# 0의 의미는 채무 이행, 즉 대출금을 상환한 사람 숫자
# 1의 의미는 채무 불이행, 즉 대출금을 상환하지 못한 사람 숫자
library("ggplot2")
ggplot2(loan_data, aes = loan_amnt)) +
geom_hitogram() +
theme_minimal()
ggplot(loan_data, aes = loan_amnt)) +
geom_hitogram() +
theme_minimal()
CrossTable(x = loan_data$loan_status)
library("ggplot")
install.packages("ggplot")
library(ggplot)
library(ggplot2)
ggplot2(loan_data, aes = loan_amnt)) +
geom_hitogram() +
theme_minimal()
ggplot(loan_data, aes = loan_amnt)) +
geom_hitogram() +
theme_minimal()
View(loan_data)
ggplot(loan_data, aes(x = date)) +
geom_line(aes(y = Low))
library(ggplot2)
ggplot(loan_data, aes = loan_amnt)) +
geom_hitogram() +
theme_minimal()
ggplot(loan_data, aes(x = loan_amnt)) +
geom_hitogram() +
theme_minimal()
ggplot(loan_data, aes(x = loan_amnt)) +
geom_histogram() +
theme_minimal()
# 0의 의미는 채무 이행, 즉 대출금을 상환한 사람 숫자
# 1의 의미는 채무 불이행, 즉 대출금을 상환하지 못한 사람 숫자
?CrossTable
# 종속변수가 되는 loan_status에 대해 데이터를 탐색합니다.
CrossTable(x = loan_data$loan_status)
# 0의 의미는 채무 이행, 즉 대출금을 상환한 사람 숫자
# 1의 의미는 채무 불이행, 즉 대출금을 상환하지 못한 사람 숫자
library(ggplot2)
ggplot(loan_data, aes(x = loan_amnt)) +
geom_histogram() +
theme_minimal()
ggplot(loan_data, aes(x = age, y = annual_inc))
ggplot(loan_data, aes(x = age, y = annual_inc)) +
# prop.r의 경우, y값에 대한 x의 비율을 알 수 있음
# prop.c의 경우, 각 변수에 대한 비율을 알 수 있음
# prop.t의 경우, 전체 테이블의 비율을 알 수 있음
# prop.chisq의 경우 각 셀에 해당하는 카이제곱의 비율을 알 수 있음
# But, 각 변수, 전체 테이블, 카이제곱은 현재로써는 필요 없음
# 위 데이터 탐색에서 봐야 하는 것은 loan_status기준으로 데이터가 불균형하다는 것에 있음
# 분류 문제 다룰 시, 이와 같은 문제에 직면하는 경우가 많음.
index_high_age = which(loan_data$age > 100)
index_high_age = which(loan_data$age > 100)
loan_data = read.csv("data/raw_loan_data.csv", strinhAsFactors = FALSE)
loan_data = read.csv("data/raw_loan_data.csv", stringsAsFactors = FALSE)
loan_data =
# 데이터 변환의 이유, 1, 0은 숫자가 아니다. 범주형이다.
#### 단계 2. 데이터 분리 ####
install.packages("caret")
?createDataPartition
?createDataPartition
??createDataPartition
library(caret)
library(doParrell)
detectCores()
detectCores()
library(plumber)
# 'plumber.R' is the location of the file shown above
pr("plumber.R") %>%
pr_run(port=8000)
install.packages("plumber")
library(plumber)
# 'plumber.R' is the location of the file shown above
pr("plumber.R") %>%
pr_run(port=8000)
library(plumber)
# 'plumber.R' is the location of the file shown above
pr("plumber.R") %>%
pr_run(port=8080)
#### 데이터 전처리 시 기본적원 방법 정리 ####
#### (2) 데이터 불러오기 ####
# setwd("~/Documents/R_edu")
loan_data <- read.csv("data/raw_loan_data.csv", stringsAsFactors = FALSE)
str(loan_data)
#### (3) 데이터 탐색하기 ####
# Load the gmodels package
library(gmodels)
# 종속변수가 되는 loan_status에 대해 데이터를 탐색합니다.
CrossTable(loan_data$loan_status)
CrossTable(x = loan_data$home_ownership,
y = loan_data$loan_status,
prop.r = TRUE, prop.c = FALSE, prop.t = FALSE, prop.chisq = FALSE)
?CrossTable
#### (4) 데이터 시각화 하기 ####
library(ggplot2)
summary(loan_data)
# 수치형 데이터 - 히스토그램으로 대출금액 파악하기
ggplot(loan_data, aes(x = loan_amnt)) +
geom_histogram(bins = 200) +
labs(title = "Total Amount of Loan") +
theme_minimal()
ggplot(loan_data, aes(x = int_rate)) +
geom_histogram(bins = 200) +
labs(title = "Interest Rate of Loan") +
theme_minimal()
ggplot(loan_data, aes(x = annual_inc / 100)) +
geom_histogram(bins = 200) +
scale_x_log10() +
labs(title = "Annual Income") +
theme_minimal()
ggplot(loan_data, aes(x = age)) +
geom_histogram() +
labs(title = "Age") +
theme_minimal()
#### (5) 이상치 제거 ####
# 시각화의 목적은 크게 두가지가 있다.
# 변수간의 관계성, 분포도 등 확인이 필요하다.
# 가장 좋은 것 중 하나는, missing data를 잡아내거나, 이상치를 잡아낼 수 있다.
# 산점도를 확인해보자
ggplot(loan_data, aes(x = age, y = annual_inc / 100)) +
geom_point(alpha = .3) +
theme_minimal()
# (1) 방법으로 제거
# 상식적으로 140세는 존재할 수 없다. (현재 의학으로는..)
# 다행히, 데이터가 1개만 존재하기 때문에, 삭제해도 무방하다.
# 이상치인 데이터의 Index를 찾아본다.
index_highage <- which(loan_data$age > 122) # 이 코드는 특정 Index를 유용하기 때문에 꼭 참고한다.
index_highage # 19486번째 사람인 것 확인
# 새로운 데이터를 만든다. loan_data2 로 저장한다.
loan_data2 <- loan_data[-index_highage, ]
# (2) 방법으로 제거
# 사분위수 Q3 + 1.5 * IQR 보다 큰것을 이상치로 판단 후 제거
outlier_cutoff <- quantile(loan_data$annual_inc, 0.75) + 1.5 * IQR(loan_data$annual_inc)
print(outlier_cutoff)
index_outlier_ROT <- which(loan_data$annual_inc > outlier_cutoff)
length(index_outlier_ROT) # 이상치로 측정된 전체 Index는 1382개수로 확인됨
loan_data_ROT <- loan_data[-index_outlier_ROT, ] # 이상치 제거한 데이터
rm(loan_data_ROT) # 이 데이터는 사용하지 않을 것이기 때문에 제거
#### (6) 결측치 처리 방법 ####
summary(loan_data2)
#### (6-1) 결측치 제거 ####
## 행 제거
# 결측치에 해당하는 Index 확인
na_index <- which(is.na(loan_data$int_rate))
length(na_index)
# Index 활용 제거
loan_data_delrow_na <- loan_data[-na_index, ]
## 변수 제거
loan_data_delcol_na <- loan_data
loan_data_delcol_na$int_rate <- NULL # 간단하게 변수 제거
#### (6-2) 중간값 대치 ####
# 우선, 결측치를 제외한 중간값을 구한다.
median_ir <- median(loan_data$int_rate, na.rm = TRUE)
# 다른 데이터로 변환
loan_data_replace <- loan_data
# 결측치 index에 중간값 대치
loan_data_replace$int_rate[na_index] <- median_ir
# 요약 통계량으로 결측치 유무 재확인
summary(loan_data_replace$int_rate)
#### (6-3) 결측치를 사용하기 ####
# 단, 중요한 것은 수치형이나 범주형이나, NA를 하나의 값으로 생각하고 치환하는 것이 핵심 포인트입니다.
loan_data$emp_cat <- rep(NA, length(loan_data$emp_length))
loan_data$emp_cat[which(loan_data$emp_length <= 15)] <- "0-15"
loan_data$emp_cat[which(loan_data$emp_length > 15 & loan_data$emp_length <= 30)] <- "15-30"
loan_data$emp_cat[which(loan_data$emp_length > 30 & loan_data$emp_length <= 45)] <- "30-45"
loan_data$emp_cat[which(loan_data$emp_length > 45)] <- "45+"
loan_data$emp_cat[which(is.na(loan_data$emp_length))] <- "Missing"
loan_data$emp_cat <- as.factor(loan_data$emp_cat)
# 근속년수에 따른 데이터를 변환하면 'Missing'으로 하나의 의미있는 값으로 치환할 수 있습니다.
# End of Document
# 로지스틱 회귀분석의 특징은 다음과 같습니다.
# 분석목적: 종속변수와 독립변수 간의 관계를 통해서 예측 모델을 생성합니다.
# 회귀분석과의 차이점: 종속변수는 반드시 범주형 변수이어야 합니다.
# 이항형: Yes/No, 다항형: 예) Iris의 Species 칼럼
# 정규성: 정규분포 대신에 이항분포를 따릅니다.
# 로짓변환: 종속변수의 출력범위를 0과 1로 조정하는 과정을 의미합니다.
#### I. 이항분류 기존 방식 ####
#### 단계 1. 데이터 가져오기 ####
# setwd("~/Documents/R_edu") 사용하지 않습니다.
loan_data <- read.csv("data/cleaned_loan_data.csv", stringsAsFactors = FALSE)
head(loan_data)
str(loan_data)
# 데이터 변환의 이유, 1, 0은 숫자가 아니다. 범주형이다.
loan_data$loan_status <- as.factor(loan_data$loan_status)
#### 단계 2. 데이터 분리 ####
library(caret)
inTrain <- createDataPartition(y = loan_data$loan_status, p=0.6, list = FALSE)
train_loan <- loan_data[inTrain,]
test_loan  <- loan_data[-inTrain,]
dim(train_loan)
#### 단계 3. 모형 개발 ####
options(scipen = 100)
null_modle <- glm(loan_status ~ 1, family = "binomial", data = loan_data)
log_model <- glm(loan_status ~ loan_amnt + grade, family = "binomial", data = loan_data)
summary(log_model)
# 카이제곱 통계량 및 유의확률 구하기
anova(null_modle, log_model, test = "Chisq")
# 승산비 구하는 법
t(exp(log_model$coefficients))
# 신뢰구간 구하기
exp(confint(log_model))
#### 단계 4. 모형 예측 ####
pred <- predict(log_model, newdata = test_loan, type = "response")
# type = "response" 속성은 예측 결과를 0~1사이의 확률값으로 반환한다.
#### 단계 5. 예측치를 이항형으로 변환 ####
# 예측치가 0.15 이상이면 1, 0.15 미만이면 0
# 일단, 0.15인지는 메뉴얼 참조
result_pred <- ifelse(pred > 0.15, 1, 0)
#### 단계 6. 분류 정확도 계산 ####
table(test_loan$loan_status, result_pred)
#### 단계 7. 분류 정확도 계산 ####
# 혼동 매트릭스에 대한 설명은 교재 참조
# 정확도 계산
(5065 + 321) / (5065 + 321 + 1401 + 485)
#### 단계 8. ROC Curve를 이용한 모델 평가 & AUC ####
library(ROCR)
par(mfrow = c(1,1))
pr <- prediction(pred, test_loan$loan_status)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
abline(0, 1, col = "red")
## --
# AUC = Area Under Curve의 뜻으로
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]; auc
#### III. 다항 로지스틱 회귀분석 해석 및 보고서 작성 ####
#### 단계 1. 패키지 설치 ####
library(dfidx)
library(mlogit) # 다항 로지스틱 회귀
library(dplyr)
#### 단계 2. 데이터 불러오기 ####
# setwd("~/Documents/R_edu") 사용하지 않습니다.
chatData <- read.csv('R_NCS_2020/3_day/data/chat-up_lines.csv', header = TRUE) %>%
mutate_if(is.character, as.factor)
#### 단계 2. 데이터 불러오기 ####
# setwd("~/Documents/R_edu") 사용하지 않습니다.
chatData <- read.csv('data/chat-up_lines.csv', header = TRUE) %>%
mutate_if(is.character, as.factor)
head(chatData)
str(chatData)
#### 단계 3. 데이터 처리 ####
# Gender에서 male이 기저 범주가 되도록 한다.
# 연구의 목적은 대화문에 대한 여성의 반응이 남성의 반응과는 다르다는 점에 기초함.
# 이러한 변경을 통해서, 주 효과들에 대한 매개변수 추정값들에 영향을 미치기는 하나, 우리의 관심사인 상호작용 항들에는 영향이 미미하다.
chatData$Gender <- relevel(chatData$Gender, ref = 2)
# 데이터 변경
# 새 데이터 프레임 <- mlogit.data(기존데이터프레임, choice = "결과변수", shape = "wide" 또는 "long")
mlChat <- mlogit.data(chatData, choice = "Success", shape = "wide")
head(mlChat)
str(mlChat)
# 위 표에 대한 설명은 교재 참조
chatModel <- mlogit(Success ~ 1 | Good_Mate + Funny + Gender + Sex + Gender:Sex + Funny:Gender,
data = mlChat,
reflevel = "No response/Walk Off",
index = c("chid", "alt"))
#### 단계 4. 모형 해석 ####
summary(chatModel)
# Likelihood ratio test : chisq = 278.52 (p.value = < 2.22e-16)
# 로그 가능도는 교재에서 본 것처럼, 자료에서 설명되지 않은 변동이 어느 정도인지 말해주는 측도이다.
# 로그 가능도의 차이 또는 변화는 새 변수가 모형을 어느 정도나 설명하는지를 나타낸다.
# 기저 모형만 분석해보자..
chatBase <- mlogit(Success ~ 0 | Sex, data = mlChat, reflevel = "No response/Walk Off")
summary(chatBase)
data.frame(exp(chatModel$coefficients))
# 이 값은 승산비이다.
# 승산비에 대한 설명은 교재를 참고한다.
# 어떻게 해석해야 할까
# 우선 기저변수인 No Response/walk off와 범주를 비교한 결과를 말한다.
# 이 계수들의 신뢰구간은 confint() 함수로 구할 수 있다.
exp(confint(chatModel))
# 각각의 해석 또한 교재를 참고한다.
# 각각의 해석 또한 교재를 참고한다.
# 각각의 해석 또한 교재를 참고한다.
# 각각의 해석 또한 교재를 참고한다.
#### I. caret 패키지 활용 머신러닝 모형 개발 ####
#### 단계 1. 병렬처리를 위한 패키지 불러오기  ####
library(caret) # 머신러닝을 위한 패키지
library(tidyverse) # 데이터 핸들링 및 시각화를 위한 패키지
library(doParallel) # 병렬처리를 위한 패키지
detectCores() # 현재 자기 컴퓨터의 코어 개수를 반환한다
cl <- parallel::makeCluster(2, setup_timeout = 0.5)
registerDoParallel(cl)
#### 단계 2. 데이터 가져오기  ####
setwd("~/Documents/R_edu")
setwd("/Volumes/T7/git/kma")
detectCores() # 현재 자기 컴퓨터의 코어 개수를 반환한다
cl <- parallel::makeCluster(2, setup_timeout = 0.5)
registerDoParallel(cl)
#### 단계 2. 데이터 가져오기  ####
loan_data <- read.csv("data/cleaned_loan_data.csv", stringsAsFactors = FALSE) # 29091 8
#### 단계 3. 데이터 전처리 ####
# 결측치 확인
sapply(loan_data, function(x) sum(is.na(x)))
# 중복값 확인
loan_data %>% duplicated() %>% sum() # 374개 확인
loan_data2 <- loan_data %>% distinct()
# 데이터 타입 확인
glimpse(loan_data)
# 사실 여기부터 모형 개발에 목적에 맞게 기저 범주를 하나씩 설정하며 봐야 하지만. 이 부분은 수강생 분들에게 맡기겠다.
loan_data2$loan_status <- factor(loan_data2$loan_status, levels = c(0, 1), labels = c("non_default", "default"))
loan_data2$grade <- as.factor(loan_data2$grade)
loan_data2$home_ownership <- as.factor(loan_data2$home_ownership)
# 한꺼번에 하고 싶습니다.
loan_data2 <- loan_data2 %>%
mutate_if(is.character, as.factor)
glimpse(loan_data2)
#### 단계 4. 데이터 분리 ####
set.seed(2018)
inx   <- createDataPartition(loan_data2$loan_status, p = 0.6, list = F)
train <- loan_data2[ inx, ]
test  <- loan_data2[-inx, ]
#### 단계 5. 모형 controler 개발 ####
# caret 패키지의 특징
control <- trainControl(
method  = "repeatedcv",
number  = 10, # 10겹
repeats = 3, # 3번
search  = "grid",
classProbs = TRUE)
#### 단계 6. 데이터의 통계적인 전처리 ####
# feature engineering
# 각각에 대한 설명은 4일차에 진행함
preProc <- c("BoxCox",
"center",
"scale",
"spatialSign",
"corr",
"zv")
## define x, y
## logistic regression
set.seed(2018)
glimpse(train)
frml <- loan_status ~ loan_amnt + grade + home_ownership + annual_inc + age + emp_cat + ir_cat
#### 단계 7.1. 모형 개발 - 로지스틱회귀 분석 ####
logis <- train(
frml,
data = train,
method     = "glm",
metric     = "Accuracy",
trControl  = control,
preProcess = preProc)
logis
